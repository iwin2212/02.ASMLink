{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Giải captcha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from capmonstercloudclient import CapMonsterClient, ClientOptions\n",
    "from capmonstercloudclient.requests import RecaptchaV2ProxylessRequest\n",
    "\n",
    "API_KEY = \"b238f538e55b7deb0da93267f61d8763\"\n",
    "WEBSITE_URL = 'https://www.shoutout.global/login?id=22wbe'\n",
    "WEBSITE_KEY = '6LfvfrEUAAAAAPg5Dt1q3UsmCwD_Z5oELX4s95eB'\n",
    "async def solve_captcha():\n",
    "    client_options = ClientOptions(api_key=API_KEY)\n",
    "    cap_monster_client = CapMonsterClient(options=client_options)\n",
    "    recaptcha2request = RecaptchaV2ProxylessRequest(\n",
    "        websiteUrl=WEBSITE_URL,\n",
    "        websiteKey=WEBSITE_KEY\n",
    "    )\n",
    "    return await cap_monster_client.solve_captcha(recaptcha2request)\n",
    "\n",
    "# responses = await solve_captcha()\n",
    "# print(responses[\"gRecaptchaResponse\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Login and get Id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import aiohttp\n",
    "\n",
    "def extract_id_from_html(html_content):\n",
    "    match = re.search(r'/userdashboard\\?id=([a-zA-Z0-9]+)', html_content)\n",
    "\n",
    "    if match:\n",
    "        id_value = match.group(1)\n",
    "        return id_value\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "async def LoginAndGetIdAsync(login_url, payload, headers):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        async with session.post(login_url, data=payload, headers=headers, allow_redirects=False) as response:\n",
    "            if response.status == 200:\n",
    "                html_content = await response.text()\n",
    "                id = extract_id_from_html(html_content)\n",
    "                if id:\n",
    "                    return id\n",
    "                else:\n",
    "                    print(\"Không tìm thấy id.\")\n",
    "            else:\n",
    "                print(f\"Error {response.status}: {await response.text()}\")\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id = be511dcfdd614aebc106fda72fb332d0e5c37645ec6cd7548893656ff18e33e34c0f0b6c000f1e479b9ced12089d16d8079c3d94eaf1731c1fe7d943bdcf2237ab5922f3ebcfb20f794505dd5dc3eb113622a388e29b1fa086b9de99913dce3f35003366bf6c7bff86\n"
     ]
    }
   ],
   "source": [
    "\n",
    "url = 'https://www.shoutout.global/checklogin'\n",
    "\n",
    "res = await solve_captcha()\n",
    "payload = {\n",
    "    \"email\": \"hunghi1090811@gmail.com\",\n",
    "    \"password\": \"c0kL2Q23iGpC\",\n",
    "    \"g-recaptcha-response\": res[\"gRecaptchaResponse\"],\n",
    "    \"encryptedID\": \"22wbe\"\n",
    "}\n",
    "headers = {\n",
    "    'Origin': 'https://www.shoutout.global'\n",
    "}\n",
    "    \n",
    "id = await LoginAndGetIdAsync(url, payload, headers)\n",
    "print(f\"id = {id}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GET data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiohttp\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "async def fetch_data(url):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        async with session.get(url) as response:            \n",
    "            if response.status == 200:\n",
    "                html_content = await response.text()\n",
    "                soup = BeautifulSoup(html_content, 'html.parser')\n",
    "                \n",
    "                total_revenue_element = soup.find(id='totalRevenueTxt')\n",
    "                return {\n",
    "                    \"salesCommissionTxt\": soup.select('.card .card-body h1.card-title')[0].get_text(strip=True),\n",
    "                    \"leadTxt\": soup.select('.card .card-body h1.card-title')[1].get_text(strip=True),\n",
    "                    \"totalRevenueTxt\": total_revenue_element.get_text(strip=True) if total_revenue_element is not None else None,\n",
    "                    \"totalCommissionTxt\": soup.select('.card .card-body .col-12 h2')[1].get_text(strip=True),\n",
    "                    \"pendingCommissionTxt\": soup.select('.card .card-body .col-12 h2')[2].get_text(strip=True)\n",
    "                }\n",
    "            else:\n",
    "                print(f\"Error: {response.status}\")\n",
    "                return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crawl data function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse, parse_qs\n",
    "\n",
    "async def crawl_data(args):\n",
    "    url, email, password = args  \n",
    "    encryptedID = parse_qs(urlparse(url).query)\n",
    "    res = await solve_captcha()\n",
    "    payload = {\n",
    "        \"email\": email,\n",
    "        \"password\": password,\n",
    "        \"g-recaptcha-response\": res[\"gRecaptchaResponse\"],\n",
    "        \"encryptedID\": encryptedID[\"id\"][0]\n",
    "    }\n",
    "    headers = {\n",
    "        'Origin': 'https://www.shoutout.global'\n",
    "    }\n",
    "\n",
    "    # print(payload)\n",
    "        \n",
    "    id = await LoginAndGetIdAsync(\"https://www.shoutout.global/checklogin\", payload, headers)\n",
    "    if id:\n",
    "        data = await fetch_data(f\"https://www.shoutout.global/userdashboard?id={id}\")\n",
    "        return data\n",
    "    else:\n",
    "        print(\"Failed to obtain ID.\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'salesCommissionTxt': '1%', 'leadTxt': '0', 'totalRevenueTxt': '$0.00', 'totalCommissionTxt': '$0.00', 'pendingCommissionTxt': '$0.00'}, {'salesCommissionTxt': '30%', 'leadTxt': 'up to5%', 'totalRevenueTxt': '$0.00', 'totalCommissionTxt': '$0.00', 'pendingCommissionTxt': '$0.00'}]\n"
     ]
    }
   ],
   "source": [
    "import pypeln as pl\n",
    "\n",
    "data = [\n",
    "    (\"https://www.shoutout.global/login?id=22wbe\", \"natashacook371sdas@gmail.com\", \"Qxwg0CN09v\"), \n",
    "    (\"https://www.shoutout.global/login?id=obbi7\", \"teamasmads@gmail.com\", \"E9vQRQmPG!a.7m6\")\n",
    "]\n",
    "stage = await pl.task.map(crawl_data, data, workers=100)\n",
    "print(stage)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
